{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import neuraltoolkit as ntk\n",
    "import glob\n",
    "import csv\n",
    "import os\n",
    "import smart_open\n",
    "import boto3\n",
    "import tqdm\n",
    "import argparse\n",
    "import fnmatch\n",
    "import io\n",
    "from natsort import natsorted\n",
    "import re\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = FS0\n",
    "ANIMAL = 'CAF62_day1'\n",
    "NF_DIR = f'/media/bs007r/CAF00062/CAF00062_2020-11-18_16-14-24/'\n",
    "#SS_DIR = '/media/HlabShare/Sleep_Scoring/CAF00049_LFP/caf4911062020/'\n",
    "OUTPUT_DIR = '../data/'\n",
    "OUTPUT_DIR_REMOTE = f\"s3://hengenlab/{ANIMAL}/Labels/\"\n",
    "NUM_CHANNELS = 64\n",
    "NF_PATTERN = r'Headstages*.bin'\n",
    "SS_PATTERN = r'*SleepStates*'\n",
    "OUTPUT_FILENAME = f\"labels_sleepstate_v2.1_{ANIMAL}\"\n",
    "FIELDS = ['activity','sleep_state','next_wake_state','next_nrem_state','next_rem_state','last_wake_state','last_nrem_state','last_rem_state','video_filename_ix','video_frame_offset','neural_filename_ix','neural_offset']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir: str, pattern: str) -> list:\n",
    "    return ntk.ntk_videos.natural_sort(glob.glob(dir+pattern))\n",
    "\n",
    "def get_remote_files(prefix: str):\n",
    "    return ntk.ntk_videos.natural_sort([file['Key'] for file in client.list_objects_v2(Bucket='hengenlab', Prefix=prefix)['Contents']])\n",
    "\n",
    "def get_s3_client():\n",
    "    with open(f\"{Path.home()}/.aws/credentials\", \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"aws_access_key_id\" in line:\n",
    "                id = re.search(r\"\\W(\\w+)\", line).group(1)\n",
    "            if \"aws_secret_access_key\" in line:\n",
    "                key = re.search(r\"\\W(\\w+)\", line).group(1)\n",
    "        return boto3.Session(aws_access_key_id=id, aws_secret_access_key=key).client(\n",
    "            \"s3\", endpoint_url=\"https://s3-central.nrp-nautilus.io\"\n",
    "        )\n",
    "\n",
    "def data_sync(ignore_error=False):\n",
    "    SW = pd.read_pickle('/media/HlabShare/james/SW_array_FINAL_Cleaned_MultipleScorerVersion.pkl')\n",
    "    neural_files = get_files(NF_DIR, NF_PATTERN)[:288]\n",
    "    print(f'Found {len(neural_files)} neural files')\n",
    "\n",
    "    timestamp_gap = 5 * 60 * 10**9\n",
    "\n",
    "    sleep_labels = SW[SW.Animal == re.search(f'(CAF\\d+)|(KDR\\d+)', ANIMAL).group()]['SW Array'].iloc[0]\n",
    "    sleep_labels[sleep_labels == 5] = 1\n",
    "    sleep_labels[sleep_labels == 4] = 2\n",
    "    if not ignore_error and abs(sleep_labels.shape[0] - 21600) > 900: raise Exception(f'Missing sleep labels (available size {sleep_labels.shape[0] // 900})')\n",
    "\n",
    "    with open(OUTPUT_DIR+OUTPUT_FILENAME+'.csv', 'w') as f:\n",
    "        w = csv.DictWriter(f, fieldnames = FIELDS)\n",
    "        w.writeheader()\n",
    "        offset_tracker = 0\n",
    "        offset_gap = 1 /15 * FS\n",
    "\n",
    "        ss_ix = 0\n",
    "        for neural_file_ix, n_file in enumerate(neural_files):\n",
    "            current_timestamp = ntk.ntk_ecube.load_raw_binary_gain_chmap(n_file, NUM_CHANNELS, 'hs64', t_only=True)[0]\n",
    "            current_file_size = (os.stat(n_file).st_size - 8) / NUM_CHANNELS / 2 \n",
    "\n",
    "            if neural_file_ix == 0: \n",
    "                last_timestamp = current_timestamp\n",
    "                last_file_size = (os.stat(n_file).st_size - 8) / NUM_CHANNELS / 2 \n",
    "                \n",
    "            else:\n",
    "                expected_timestamp = last_timestamp + timestamp_gap\n",
    "                if not ignore_error and current_timestamp - expected_timestamp > 10**10: raise Exception(f'Inconsistent timestamp: last {last_timestamp} current {current_timestamp}')\n",
    "                if not ignore_error and last_file_size / FS * 10**9 != current_timestamp - last_timestamp : raise Exception(f'Inconsistent file size {last_file_size}')\n",
    "\n",
    "            offset_checkpoint = offset_tracker\n",
    "            \n",
    "            while (offset_tracker-offset_checkpoint <= current_file_size) and ss_ix < sleep_labels.shape[0]:\n",
    "                entry = {\n",
    "                    'activity': -1,\n",
    "                    'sleep_state': int(sleep_labels[ss_ix]),\n",
    "                    'next_wake_state': -1,\n",
    "                    'next_nrem_state': -1,\n",
    "                    'next_rem_state': -1,\n",
    "                    'last_wake_state': -1,\n",
    "                    'last_nrem_state': -1,\n",
    "                    'last_rem_state': -1,\n",
    "                    'video_filename_ix': 0,\n",
    "                    'video_frame_offset': 0,\n",
    "                    'neural_filename_ix': neural_file_ix,\n",
    "                    'neural_offset': round(offset_tracker - offset_checkpoint)\n",
    "                }\n",
    "                w.writerow(entry)\n",
    "                offset_tracker += offset_gap\n",
    "                ss_ix = round(offset_tracker) // FS // 4\n",
    "                \n",
    "            last_timestamp = current_timestamp\n",
    "            last_file_size = current_file_size\n",
    "\n",
    "def save_npz(client):\n",
    "    with open(\n",
    "        OUTPUT_DIR + OUTPUT_FILENAME + \".csv\",\n",
    "    ) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader, None)\n",
    "        try:\n",
    "            videofiles = np.array([re.search('Video/(\\S+.mp4)', file).groups()[0] for file in get_remote_files(f'{ANIMAL}/Video/')])\n",
    "        except:\n",
    "            videofiles = np.array(['dummy'])\n",
    "            \n",
    "        neuralfiles = np.array([re.search('Headstages\\S+', file).group(0) for file in get_remote_files(f'{ANIMAL}/Neural_Data/')])\n",
    "        labels_matrix = np.array(\n",
    "            [tuple(line) for line in reader],\n",
    "            dtype=[\n",
    "                (\"activity\", \"i1\"),\n",
    "                (\"sleep_state\", \"i1\"),\n",
    "                (\"next_wake_state\", \"<i8\"),\n",
    "                (\"next_nrem_state\", \"<i8\"),\n",
    "                (\"next_rem_state\", \"<i8\"),\n",
    "                (\"last_wake_state\", \"<i8\"),\n",
    "                (\"last_nrem_state\", \"<i8\"),\n",
    "                (\"last_rem_state\", \"<i8\"),\n",
    "                (\"video_filename_ix\", \"<i4\"),\n",
    "                (\"video_frame_offset\", \"<i4\"),\n",
    "                (\"neural_filename_ix\", \"<i4\"),\n",
    "                (\"neural_offset\", \"<i8\"),\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        with smart_open.open(\n",
    "            OUTPUT_DIR_REMOTE + OUTPUT_FILENAME + \".npz\",\n",
    "            \"wb\",\n",
    "            transport_params=dict(client=client),\n",
    "        ) as of:\n",
    "            np.savez(\n",
    "                of,\n",
    "                labels_matrix=labels_matrix,\n",
    "                video_files=videofiles,\n",
    "                neural_files=neuralfiles,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 264 neural files\n"
     ]
    }
   ],
   "source": [
    "client = get_s3_client()\n",
    "data_sync(ignore_error=True)\n",
    "save_npz(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "james_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
